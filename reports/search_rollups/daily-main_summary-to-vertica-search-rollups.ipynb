{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "READ_VERSION = 3\n",
    "READ_STEM = 's3://telemetry-parquet/main_summary/v{}/'.format(READ_VERSION)\n",
    "READ_TAIL = 'submission_date_s3={}/'\n",
    "DAY_READ_PATH = READ_STEM + READ_TAIL\n",
    "\n",
    "WRITE_VERSION = 1\n",
    "BASH_WRITE_STEM = 's3://net-mozaws-prod-us-west-2-pipeline-analysis/' \\\n",
    "    'spenrose/search/to_vertica/'\n",
    "ROLLUP_WRITE_STEM = BASH_WRITE_STEM + 'daily/'\n",
    "MANIFEST_WRITE_STEM = BASH_WRITE_STEM + 'manifests/'\n",
    "\n",
    "PROFILE_DAY = 'profile_day'\n",
    "PROFILE_COLUMN = 'concat(client_id, submission_date) as {}'.format(PROFILE_DAY)\n",
    "def add_profile_day(frame):\n",
    "    return frame.selectExpr(\n",
    "        \"*\",\n",
    "        PROFILE_COLUMN\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "TEMP_TABLE_TEMPLATE = 'rollup_temp_{}'\n",
    "\n",
    "# SELECT_ROLLUP_TEMPLATE says: gather all permutations of\n",
    "# submission_date, country, search_provider, default_provider,\n",
    "# locale, distribution_id and count:\n",
    "# 1) How many searches fall into each permutation? -> search_count\n",
    "# 2) How many profiles fall into each bucket -> profile_count\n",
    "# 3) What share of total profiles does this bucket represent? -> profile_share\n",
    "# The distinction between profile_count and profile_share is necessary\n",
    "# because on a given submission_date a single user of a profile may switch\n",
    "# default search engine (or locale or geo), or a profile may be shared by\n",
    "# multiple users on a day (causing all the other fields to vary if the\n",
    "# users are on widely distributed machines).\n",
    "SELECT_ROLLUP_TEMPLATE = \"\"\"\n",
    "SELECT\n",
    "  submission_date,\n",
    "  search_provider,\n",
    "  sum(search_count) as search_count,\n",
    "  country,\n",
    "  locale,\n",
    "  distribution_id,\n",
    "  default_provider,\n",
    "  count(distinct profile_day) as profile_count,\n",
    "  sum(profile_share) as profile_share\n",
    "FROM\n",
    "  {}\n",
    "WHERE\n",
    "  ((search_count > -1) OR (search_count is null))\n",
    "GROUP BY\n",
    "  submission_date, country, search_provider, default_provider, locale, distribution_id\n",
    "\"\"\"\n",
    "\n",
    "# SELECT_SHARE says: given a single profile_day with N permutations of\n",
    "# (search_provider, country, locale, distribution_id, default_provider),\n",
    "# N = an integer > 0, assign each row a profile_share of 1/N.\n",
    "# Example #1: a user switches default mid-day -> she generates two\n",
    "# rows, each with profile_count = 1 and profile_share = 0.5.\n",
    "# Example #2: a profile is cloned to ten laptops, the users of which\n",
    "# change default engines, travel across country borders, etc. ->\n",
    "# they generate N rows whose profile_counts sum to 10 and whose\n",
    "# profile_share sums to 1.0.\n",
    "SELECT_SHARE = \"\"\"\n",
    "SELECT\n",
    "  {}.*,\n",
    "  share_table.profile_share\n",
    "FROM\n",
    "  {}, (\n",
    "    SELECT\n",
    "      profile_day,\n",
    "      1.0/count(*) AS profile_share\n",
    "    FROM\n",
    "      {}\n",
    "    GROUP BY profile_day)\n",
    "  share_table\n",
    "WHERE\n",
    "  {}.profile_day = share_table.profile_day\n",
    "\"\"\"\n",
    "\n",
    "def roll_up_searches(frame):\n",
    "    try:\n",
    "        frame[PROFILE_DAY]\n",
    "    except Exception:\n",
    "        frame = add_profile_day(frame)\n",
    "    frame.repartition(\"profile_day\")\n",
    "    nulls_frame = frame.where('search_counts is null')\n",
    "    temp_table = TEMP_TABLE_TEMPLATE.format(int(time.time()))\n",
    "    select_rollup = SELECT_ROLLUP_TEMPLATE.format(temp_table)\n",
    " \n",
    "    exploded = frame.selectExpr(\n",
    "        \"submission_date\",\n",
    "        \"profile_day\",\n",
    "        \"country\",\n",
    "        \"locale\",\n",
    "        \"distribution_id\",\n",
    "        \"default_search_engine as default_provider\",\n",
    "        \"explode(search_counts) as search_counts\")\n",
    "    unwrapped = exploded.selectExpr(\n",
    "        \"submission_date\",\n",
    "        \"profile_day\",\n",
    "        \"country\",\n",
    "        \"locale\",\n",
    "        \"distribution_id\",\n",
    "        \"default_provider\",\n",
    "        \"search_counts.engine as search_provider\",\n",
    "        \"search_counts.count as search_count\")\n",
    "    unwrapped_nulls = nulls_frame.selectExpr(\n",
    "        \"submission_date\",\n",
    "        \"profile_day\",\n",
    "        \"country\",\n",
    "        \"locale\",\n",
    "        \"distribution_id\",\n",
    "        \"default_search_engine as default_provider\",\n",
    "        \"'NO_SEARCHES' as search_provider\",\n",
    "        \"0 as search_count\"\n",
    "    )\n",
    "    unwrapped_all = unwrapped.unionAll(unwrapped_nulls)\n",
    "    share_temp = 'share_temp_{}'.format(int(time.time()))\n",
    "    select_share = SELECT_SHARE.format(\n",
    "        share_temp, share_temp, share_temp, share_temp)\n",
    "    unwrapped_all.registerTempTable(share_temp)\n",
    "    shared = sqlContext.sql(select_share)\n",
    "    shared.registerTempTable(temp_table)\n",
    "    searches_by_period = sqlContext.sql(select_rollup)\n",
    "    return searches_by_period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import datetime as DT, subprocess, sys\n",
    "BASENAME = 'daily-rollup-of-searches-submitted-{}-format-{}.csv'\n",
    "def get_s3_write_path(date):\n",
    "    return ROLLUP_WRITE_STEM + BASENAME.format(date, WRITE_VERSION)\n",
    "\n",
    "def main(date=None, rerun=False):\n",
    "    date = date or DT.date.today().isoformat()\n",
    "    if not rerun:\n",
    "        # See if the output exists already.\n",
    "        cmd = \"aws s3 ls {}\".format(get_s3_write_path(date))\n",
    "        exists = not subprocess.call(cmd, shell=True)\n",
    "        if exists:\n",
    "            bn = BASENAME.format(date, WRITE_VERSION)\n",
    "            report(bn, \"not written\", [\"already exists\"])\n",
    "            sys.exit(1)\n",
    "        \n",
    "    # This will throw an AnalysisException if the path doesn't exist.\n",
    "    day_path = DAY_READ_PATH.format(date.replace('-', ''))\n",
    "    local = []\n",
    "    print \"starting\", date, \"at:\", str(DT.datetime.now())[:19]\n",
    "    for i in range(100):\n",
    "        print i,\n",
    "        sys.stdout.flush()\n",
    "        sample_path = day_path + 'sample_id={}/'.format(i)\n",
    "        frame = sqlContext.read.parquet(sample_path)\n",
    "        search_frame = roll_up_searches(frame)\n",
    "        results = search_frame.collect()\n",
    "        local.extend(results)\n",
    "        search_frame.unpersist()\n",
    "        frame.unpersist()\n",
    "    print \"finished at:\", str(DT.datetime.now())[:19]\n",
    "    return local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def to_iso(eight):\n",
    "    return '-'.join([eight[:4], eight[4:6], eight[6:]])\n",
    "\n",
    "import csv, subprocess, sys\n",
    "\n",
    "def coalesce(rows):\n",
    "    d = {}\n",
    "    for r in rows:\n",
    "        k = (r.submission_date, r.search_provider or 'NO_SEARCHES', r.country,\n",
    "             r.locale or 'xx', r.distribution_id or 'MOZILLA',\n",
    "             r.default_provider or 'NO_DEFAULT')\n",
    "        if k in d:\n",
    "            searches, people, share = d[k]\n",
    "        else:\n",
    "            searches, people, share = 0, 0, 0\n",
    "        d[k] = (searches + (r.search_count or 0),\n",
    "                people + r.profile_count,\n",
    "                share + round(r.profile_share, 2))\n",
    "    return d\n",
    "\n",
    "def dump_dict(d, basename):\n",
    "    bad = []\n",
    "    processed = DT.date.today().strftime('%Y-%m-%d')\n",
    "    with open(basename, 'w') as f:\n",
    "        writer = csv.writer(f)\n",
    "        for k, v in d.iteritems():\n",
    "            (submission_date, search_provider, country, locale, \n",
    "             distribution_id, default_provider) = k\n",
    "            search_count, profile_count, profile_share = v\n",
    "            try:\n",
    "                row = (to_iso(submission_date), search_provider,\n",
    "                       str(search_count), country, locale,\n",
    "                       distribution_id,\n",
    "                       default_provider,\n",
    "                       str(profile_count), str(profile_share), processed)\n",
    "                row = [s.encode(\"utf-8\") for s in row]\n",
    "                writer.writerow(row)\n",
    "            except Exception:\n",
    "                bad.append((k, v))\n",
    "    copy = \"aws s3 cp {} {}\".format(basename, ROLLUP_WRITE_STEM)\n",
    "    subprocess.check_call(copy, shell=True)\n",
    "    return bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def write_manifest(date, version, *paths):\n",
    "    text = '\\n'.join(paths) + '\\n'\n",
    "    tries = version + 10\n",
    "    while True:\n",
    "        manifest_basename = 'daily-search-rollup-manifest-{}-v{}.txt'.format(date, version)\n",
    "        path = MANIFEST_WRITE_STEM + manifest_basename\n",
    "        if subprocess.call(\"aws s3 ls {}\".format(path), shell=True):\n",
    "            break\n",
    "        version += 1\n",
    "        if version == tries:\n",
    "            raise Exception(\"Can't find unwritten manifest at {}\".format(path))\n",
    "    with open(manifest_basename, 'w') as f:\n",
    "        f.write(text)\n",
    "    copy = \"aws s3 cp {} {}\".format(manifest_basename, MANIFEST_WRITE_STEM)\n",
    "    subprocess.check_call(copy, shell=True)\n",
    "\n",
    "import smtplib\n",
    "from email.message import Message\n",
    "\n",
    "owner = 'spenrose' # XXX read from environment\n",
    "owner += '@mozilla.com'\n",
    "def report(date, path, bad):\n",
    "    subject = \"Daily search rollups for {}\".format(date)\n",
    "    if bad:\n",
    "        subject += \": %d failures\" % len(bad)\n",
    "    body = 'written to {}'.format(path)\n",
    "    if bad:\n",
    "        body += '\\nproblem rows:\\n'\n",
    "        for row in bad[:10]:\n",
    "            body += str(row) + '\\n'\n",
    "    \n",
    "    msg = Message()\n",
    "    msg.set_payload(body)\n",
    "    msg['Subject'] = subject\n",
    "    msg['To'] = owner\n",
    "    msg['From'] = owner\n",
    "    smtp = smtplib.SMTP('localhost')\n",
    "    smtp.sendmail(owner, owner, msg.as_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "date = (DT.date.today()-DT.timedelta(1)).isoformat()\n",
    "rows = main(date)\n",
    "dicty = coalesce(rows)\n",
    "basename = BASENAME.format(date, WRITE_VERSION)\n",
    "bad = dump_dict(dicty, basename)\n",
    "path = get_s3_write_path(date)\n",
    "try:\n",
    "    write_manifest(DT.date.today().isoformat(), 1, path)\n",
    "except Exception:\n",
    "    report(date, path, [\"Manifest writing failed\"])\n",
    "report(date, path, bad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
